{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install clearml\n",
    "!pip install torch\n",
    "!pip install torchinfo\n",
    "!pip install torchmetrics\n",
    "!pip install git+https://github.com/Yikai-Liao/symusic\n",
    "!pip install git+https://github.com/Natooz/MidiTok\n",
    "!pip install scikit-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T06:23:46.705229Z",
     "iopub.status.busy": "2024-08-22T06:23:46.704763Z",
     "iopub.status.idle": "2024-08-22T06:24:03.669156Z",
     "shell.execute_reply": "2024-08-22T06:24:03.667570Z",
     "shell.execute_reply.started": "2024-08-22T06:23:46.705200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n",
      "Loaded tokenizer:\n",
      "Special tokens: ['PAD_None', 'BOS_None', 'EOS_None', 'MASK_None']\n",
      "Special tokens ids: [0, 1, 2, 3]\n",
      "ClearML Task: created new task id=f783b289277745adb1ae60684e319bb0\n",
      "2024-08-22 06:23:52,176 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "ClearML results page: https://app.clear.ml/projects/c282730e9b304dab984abd9d1dea0d29/experiments/f783b289277745adb1ae60684e319bb0/output/log\n",
      "Loaded model:\n",
      "TransformerModel(\n",
      "  (embedding): Embedding(10000, 256, padding_idx=0)\n",
      "  (transformer_layers): ModuleList(\n",
      "    (0-3): 4 x TransformerBlock(\n",
      "      (mha): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (ffn): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      )\n",
      "      (layernorm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "      (layernorm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (dense): Linear(in_features=256, out_features=10000, bias=True)\n",
      "  (softmax): Softmax(dim=-1)\n",
      ")\n",
      "Loaded tokenizer:\n",
      "Special tokens: ['PAD_None', 'BOS_None', 'EOS_None', 'MASK_None']\n",
      "Special tokens ids: [0, 1, 2, 3]\n",
      "2024-08-22 06:24:02,790 - clearml - INFO - Dataset.get() did not specify alias. Dataset information will not be automatically logged in ClearML Server.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/miditok/tokenizations/remi.py:77: UserWarning:\n",
      "\n",
      "Attribute controls are not compatible with 'config.one_token_stream_for_programs' and multi-vocabulary tokenizers. Disabling them from the config.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not find Dataset project/name/version ('GigMate', 'LakhMidiCleanDatasetFull', '1.0.0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Define early stopping callback (using ReduceLROnPlateau)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(optimizer\u001b[38;5;241m=\u001b[39moptimizer, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 50\u001b[0m train_loader, test_loader \u001b[38;5;241m=\u001b[39m \u001b[43mget_data_loaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, entry \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;66;03m# Move data to GPU if available\u001b[39;00m\n",
      "File \u001b[0;32m/notebooks/dataset.py:90\u001b[0m, in \u001b[0;36mget_data_loaders\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_data_loaders\u001b[39m():\n\u001b[1;32m     89\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m get_tokenizer()\n\u001b[0;32m---> 90\u001b[0m     train_ds, test_ds \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     collator \u001b[38;5;241m=\u001b[39m DataCollator(\n\u001b[1;32m     92\u001b[0m         pad_token_id\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpad_token_id,\n\u001b[1;32m     93\u001b[0m         copy_inputs_as_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     94\u001b[0m         shift_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     95\u001b[0m         labels_pad_idx\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpad_token_id,\n\u001b[1;32m     96\u001b[0m     )\n\u001b[1;32m     97\u001b[0m     train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_ds, batch_size\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mbatch_size, collate_fn\u001b[38;5;241m=\u001b[39mcollator, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/notebooks/dataset.py:83\u001b[0m, in \u001b[0;36mget_dataset\u001b[0;34m(tokenizer)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_dataset\u001b[39m(tokenizer):\n\u001b[0;32m---> 83\u001b[0m     remote_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mget_remote_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     directory \u001b[38;5;241m=\u001b[39m remote_dataset\u001b[38;5;241m.\u001b[39mget_local_copy()\n\u001b[1;32m     85\u001b[0m     train_ds, test_ds \u001b[38;5;241m=\u001b[39m create_pt_datasets(directory, max_seq_len\u001b[38;5;241m=\u001b[39mget_max_seq_len(), tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n",
      "File \u001b[0;32m/notebooks/dataset.py:71\u001b[0m, in \u001b[0;36mget_remote_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_remote_dataset\u001b[39m():\n\u001b[0;32m---> 71\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;43;03m#        dataset_id='29c113071b6646fdaae0d314c775516f',  \u001b[39;49;00m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_project\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGigMate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLakhMidiCleanDatasetFull\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_tags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfull\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1.0.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_completed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_published\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/clearml/datasets/dataset.py:1766\u001b[0m, in \u001b[0;36mDataset.get\u001b[0;34m(cls, dataset_id, dataset_project, dataset_name, dataset_tags, only_completed, only_published, include_archived, auto_create, writable_copy, dataset_version, alias, overridable, shallow_search, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     dataset_id, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_dataset_id(\n\u001b[1;32m   1750\u001b[0m         dataset_project\u001b[38;5;241m=\u001b[39mdataset_project,\n\u001b[1;32m   1751\u001b[0m         dataset_name\u001b[38;5;241m=\u001b[39mdataset_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1763\u001b[0m         shallow_search\u001b[38;5;241m=\u001b[39mshallow_search\n\u001b[1;32m   1764\u001b[0m     )\n\u001b[1;32m   1765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dataset_id \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m auto_create:\n\u001b[0;32m-> 1766\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1767\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find Dataset \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1768\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dataset_id \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject/name/version\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1769\u001b[0m                 dataset_id \u001b[38;5;28;01mif\u001b[39;00m dataset_id \u001b[38;5;28;01melse\u001b[39;00m (dataset_project, dataset_name, dataset_version),\n\u001b[1;32m   1770\u001b[0m             )\n\u001b[1;32m   1771\u001b[0m         )\n\u001b[1;32m   1772\u001b[0m orig_dataset_id_ \u001b[38;5;241m=\u001b[39m dataset_id\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m alias \u001b[38;5;129;01mand\u001b[39;00m overridable \u001b[38;5;129;01mand\u001b[39;00m running_remotely():\n",
      "\u001b[0;31mValueError\u001b[0m: Could not find Dataset project/name/version ('GigMate', 'LakhMidiCleanDatasetFull', '1.0.0')"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Monitor: Could not detect iteration reporting, falling back to iterations as seconds-from-start\n"
     ]
    }
   ],
   "source": [
    "from train import train_model\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T08:46:49.573805Z",
     "iopub.status.busy": "2024-08-18T08:46:49.573356Z",
     "iopub.status.idle": "2024-08-18T08:46:50.475449Z",
     "shell.execute_reply": "2024-08-18T08:46:50.474216Z",
     "shell.execute_reply.started": "2024-08-18T08:46:49.573768Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T09:18:13.168076Z",
     "iopub.status.busy": "2024-08-18T09:18:13.167342Z",
     "iopub.status.idle": "2024-08-18T09:18:22.288368Z",
     "shell.execute_reply": "2024-08-18T09:18:22.287048Z",
     "shell.execute_reply.started": "2024-08-18T09:18:13.168050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted (tensor(8032), [(tensor([[[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.4268, 0.5732, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.4591, 0.2299, 0.3111,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0013, 0.0015, 0.0017,  ..., 0.0017, 0.0000, 0.0000],\n",
      "         [0.0012, 0.0022, 0.0019,  ..., 0.0017, 0.0016, 0.0000],\n",
      "         [0.0018, 0.0011, 0.0011,  ..., 0.0018, 0.0019, 0.0022]]]), tensor([[[ 0.3546, -1.5463, -0.4309,  ...,  0.1615,  0.3449,  0.2542],\n",
      "         [-0.1645,  1.0408,  1.5975,  ...,  0.8508, -0.8055,  0.7852],\n",
      "         [ 0.6472, -0.3673, -0.4719,  ..., -0.3591, -0.1484, -0.5040],\n",
      "         ...,\n",
      "         [-1.5395, -0.7208,  0.2643,  ..., -1.1074,  0.3187,  0.7764],\n",
      "         [ 0.2862,  0.8020,  0.5028,  ..., -0.5935,  0.2473, -0.8472],\n",
      "         [ 0.0792, -0.2353,  0.6726,  ...,  1.6569, -1.1159,  1.4272]]])), (tensor([[[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.5132, 0.4868, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.3615, 0.3948, 0.2437,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0017, 0.0040, 0.0024,  ..., 0.0023, 0.0000, 0.0000],\n",
      "         [0.0018, 0.0018, 0.0019,  ..., 0.0022, 0.0020, 0.0000],\n",
      "         [0.0017, 0.0021, 0.0016,  ..., 0.0022, 0.0018, 0.0018]]]), tensor([[[ 0.2536, -0.6033,  0.0869,  ...,  0.5486,  0.2896,  1.0002],\n",
      "         [ 0.2963,  1.2209,  1.5778,  ...,  1.5472, -1.0957,  1.0309],\n",
      "         [ 0.9240,  0.3064, -0.3796,  ...,  0.2257, -0.4658, -0.0797],\n",
      "         ...,\n",
      "         [-1.5295, -0.7866,  0.0948,  ..., -0.8402,  0.4361,  0.7451],\n",
      "         [ 0.7353,  0.6431,  0.6213,  ..., -0.6813,  0.3171, -0.4544],\n",
      "         [ 0.2242, -0.6182,  0.8768,  ...,  2.0608, -1.1352,  1.6155]]])), (tensor([[[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.4251, 0.5749, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.3018, 0.3258, 0.3724,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0016, 0.0017, 0.0017,  ..., 0.0020, 0.0000, 0.0000],\n",
      "         [0.0022, 0.0015, 0.0018,  ..., 0.0020, 0.0027, 0.0000],\n",
      "         [0.0018, 0.0014, 0.0013,  ..., 0.0018, 0.0020, 0.0019]]]), tensor([[[ 0.5122, -1.2685,  0.5489,  ...,  0.2267,  0.2131,  1.0535],\n",
      "         [ 0.8562,  0.1363,  1.7011,  ...,  1.8916, -0.8552,  0.9776],\n",
      "         [ 0.6384, -0.2222, -0.1459,  ...,  0.3116, -0.3667, -0.0043],\n",
      "         ...,\n",
      "         [-1.5058, -1.3654,  0.3092,  ..., -0.7534,  0.5720,  0.5254],\n",
      "         [ 0.4956,  0.5326,  0.5236,  ..., -0.8066,  0.7172, -0.4127],\n",
      "         [ 0.1138, -1.1489,  0.5223,  ...,  2.0211, -1.5850,  1.0994]]])), (tensor([[[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.5816, 0.4184, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.3957, 0.2886, 0.3156,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0019, 0.0021, 0.0018,  ..., 0.0024, 0.0000, 0.0000],\n",
      "         [0.0016, 0.0021, 0.0020,  ..., 0.0020, 0.0015, 0.0000],\n",
      "         [0.0019, 0.0015, 0.0015,  ..., 0.0025, 0.0019, 0.0016]]]), tensor([[[ 0.5552, -0.4194,  0.5411,  ...,  0.3213,  0.2364,  1.5023],\n",
      "         [ 1.9543,  0.4639,  1.2133,  ...,  1.6078, -0.9580,  0.8073],\n",
      "         [ 1.3345,  0.6046, -0.1819,  ...,  0.0368, -0.8065,  0.8332],\n",
      "         ...,\n",
      "         [-0.7893, -1.4242,  0.3053,  ..., -1.1339,  0.6960,  0.2722],\n",
      "         [ 1.1927,  0.5017,  0.3927,  ..., -1.0031,  0.4973, -0.0501],\n",
      "         [ 0.0258, -1.0614,  0.4533,  ...,  1.5563, -1.9075,  1.0474]]]))])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def sample_from_logits(logits, temperature):\n",
    "    # If temp is 0 then next_token is the argmax of logits\n",
    "    if temperature == 0.0:\n",
    "        next_token = torch.argmax(logits, dim=1)\n",
    "    \n",
    "    # If temp is not 0 then next_token is sampled out of logits\n",
    "    else:\n",
    "        logits = logits / temperature\n",
    "        next_token = torch.multinomial(torch.softmax(logits, dim=1), num_samples=1)\n",
    "    return next_token\n",
    "\n",
    "def predict_next_note(model, input_sequence, temperature=0, past_key_values=None):\n",
    "    inp = torch.tensor(input_sequence).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inp)\n",
    "        logits, key_values = model(inp, past_key_values=past_key_values, use_cache=True)\n",
    "    predicted_tokens = sample_from_logits(logits[0], temperature)\n",
    "    next_token = predicted_tokens[-1].squeeze()\n",
    "    return next_token, key_values\n",
    "\n",
    "entry = next(enumerate(train_loader))\n",
    "\n",
    "input_sequence = entry[1]['input_ids'][0]  # Example input sequence\n",
    "predicted_note = predict_next_note(get_model(), input_sequence, 0.2)\n",
    "print('predicted', predicted_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T09:27:58.064834Z",
     "iopub.status.busy": "2024-08-18T09:27:58.064515Z",
     "iopub.status.idle": "2024-08-18T09:29:13.331731Z",
     "shell.execute_reply": "2024-08-18T09:29:13.328868Z",
     "shell.execute_reply.started": "2024-08-18T09:27:58.064809Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/_device.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m key_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m next_note \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:  \u001b[38;5;66;03m# 2 is the end of sequence code\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     next_note, key_values \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_next_note\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     meaning \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[95], line 20\u001b[0m, in \u001b[0;36mpredict_next_note\u001b[0;34m(model, input_sequence, temperature, past_key_values)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     19\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inp)\n\u001b[0;32m---> 20\u001b[0m     logits, key_values \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m predicted_tokens \u001b[38;5;241m=\u001b[39m sample_from_logits(logits[\u001b[38;5;241m0\u001b[39m], temperature)\n\u001b[1;32m     22\u001b[0m next_token \u001b[38;5;241m=\u001b[39m predicted_tokens[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[97], line 70\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[0;34m(self, inputs, past_key_values, use_cache)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n\u001b[1;32m     69\u001b[0m     x, key_value \u001b[38;5;241m=\u001b[39m layer(x, past_key_value\u001b[38;5;241m=\u001b[39mpast_key_value, use_cache\u001b[38;5;241m=\u001b[39muse_cache)\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mkey_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[1;32m     71\u001b[0m     new_key_values\u001b[38;5;241m.\u001b[39mappend(key_value)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "input_sequence = entry[1]['input_ids'][0][250:]\n",
    "output_sequence = torch.tensor(input_sequence)\n",
    "next_sequence = output_sequence[-min(len(output_sequence), max_seq_len) - 1:]\n",
    "last_note = len(next_sequence) - 1\n",
    "\n",
    "next_note = -1\n",
    "i = 0\n",
    "key_values = None\n",
    "while i < 100 and next_note != 2:  # 2 is the end of sequence code\n",
    "    next_note, key_values = predict_next_note(get_model(), next_sequence, temperature=0.2, past_key_values=key_values)\n",
    "    meaning = ''\n",
    "    try:\n",
    "        sequence = TokSequence(ids=[next_note.item()], are_ids_encoded=True)\n",
    "        tokenizer.decode_token_ids(sequence)\n",
    "        tokenizer.complete_sequence(sequence)\n",
    "        meaning = sequence.tokens\n",
    "    except Exception as e:\n",
    "        print('Error', e)\n",
    "    print(f'token {i}: {next_note}, meaning: {meaning}')\n",
    "    output_sequence = torch.cat([output_sequence, next_note.unsqueeze(0)], 0)\n",
    "    next_sequence = torch.cat([next_sequence[1:], next_note.unsqueeze(0)], 0)\n",
    "    i += 1\n",
    "\n",
    "print(f'output: {output_sequence}')\n",
    "print(f'output shape: {output_sequence.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T09:29:18.715768Z",
     "iopub.status.busy": "2024-08-18T09:29:18.715448Z",
     "iopub.status.idle": "2024-08-18T09:29:18.732935Z",
     "shell.execute_reply": "2024-08-18T09:29:18.731907Z",
     "shell.execute_reply.started": "2024-08-18T09:29:18.715744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokSequence(tokens=[], ids=[1214, 2241, 1131, 733, 783, 1805, 975, 1874, 788, 1805, 2840, 786, 1880, 724, 3510, 733, 4182, 705, 8713, 3608, 786, 196, 943, 2707, 567, 1178, 1227, 609, 2496, 115, 1214, 590, 2871, 6489, 943, 114, 1214, 1942, 1619, 1432, 904, 1238, 788, 2200, 783, 2200, 2398, 611, 3569, 1787, 1642, 829, 1739, 8005, 7684, 1703, 113, 1214, 605, 4077, 611, 1103, 1453, 592, 4243, 101, 1214, 1992, 897, 3835, 3712, 113, 1214, 4571, 2398, 663, 659, 588, 4077, 663, 208, 967, 5628, 114, 1214, 1885, 1619, 840, 904, 798, 678, 996, 806, 1106, 2624, 663, 4155, 664, 1642, 724, 2369, 611, 869, 2067, 3323, 2290, 114, 1214, 574, 3053, 786, 6693, 6112, 967, 4271, 115, 1214, 1629, 1619, 1391, 904, 2052, 678, 1805, 806, 2052, 2398, 786, 4406, 611, 3569, 724, 2369, 5057, 1178, 1227, 609, 3835, 4271, 2496, 116, 1214, 600, 4077, 786, 3221, 5053, 869, 3323, 114, 1214, 2058, 2624, 5231, 3835, 1920, 2703, 3343, 116, 1214, 605, 3053, 696, 1784, 1325, 4483, 967, 120, 1214, 580, 571, 2394, 1533, 837, 2065, 904, 2065, 783, 2065, 7642, 611, 1220, 805, 2096, 870, 2624, 765, 3569, 1262, 1880, 1346, 1739, 1054, 897, 2137, 3323, 1703, 115, 1214, 603, 2588, 611, 2196, 8296, 2748, 2006, 1568, 757, 2624, 1806, 8161, 3027, 113, 1214, 2506, 1934, 677, 975, 660, 788, 733, 1568, 877, 1252, 698, 783, 733, 3756, 786, 1220, 789, 2096, 870, 2624, 757, 659, 589, 2944, 786, 196, 943, 122, 1214, 1311, 1880, 660, 1540, 611, 3510, 7109, 1178, 609, 2496, 115, 1214, 8800, 7218, 2528, 2624, 870, 659, 5283, 3742, 7890, 3426, 2888, 9950, 7054, 402, 7594, 3968, 5903, 4514, 2024, 4257, 6914, 7265, 8270, 4903, 4723, 2598, 3101, 8619, 6502, 963, 9131, 8194, 8696, 6220, 1083, 4999, 3622, 5618, 6637, 9581, 9229, 2172, 3734, 8568, 8225, 1869, 4051, 4146, 9759, 1718, 884, 3999, 3486, 1367, 9175, 1684, 7206, 3896, 4670, 4612, 9250, 1768, 348, 3646, 1634, 3142, 3568, 4926, 156, 2247, 9490, 6266, 905, 529, 5233, 6764, 4953, 6808, 938, 8529, 2644, 5594, 1357, 2525, 3530, 1741, 6308, 1265, 9352, 7603, 8753, 6133, 5650, 2553, 2073, 1440, 2085, 8057, 8015, 7254, 9246, 23, 9979, 3725, 3085, 9585, 9520, 5265, 1712, 6504, 717, 7070, 4697, 5637, 1413, 6105, 3074, 5722, 406, 424, 379, 5248, 5802, 4620, 5477, 7816, 8229, 6382, 5510, 4114, 8833, 1560, 6520, 995, 904, 6189, 2681, 3656, 4142, 7759, 827, 5725, 9885, 6390, 8330, 8938, 6838, 7540, 9707, 5642, 75, 2166, 412, 9988, 8551, 4790, 2212, 3804, 7004, 8064, 198, 3282, 584, 3977, 8586, 9088, 5763, 5036, 1678, 9058, 2520, 3908, 3222, 4772, 9350, 7779, 8840, 3674, 8645, 4317, 7729, 5661, 1602, 6429, 9008, 4842, 848, 6582, 7351, 7740, 2843, 6549, 9396, 3757, 8560, 1395, 7737, 8657, 8625, 8340, 3624, 1729, 8239, 2080, 5231, 7426, 9177, 7324, 2022, 2097, 7996, 2886, 5887, 3643, 5068, 5436, 5625, 9331, 2611, 5080, 9950, 5530, 4999, 1487, 8765, 945, 5216, 3781, 3191, 9396, 3751, 4948, 6706, 7410, 9460, 5231, 8998, 1927, 4211, 1222, 7861, 7447, 8024, 6754, 6911, 4376, 3492, 3605, 3758, 572, 7822, 6452, 9207, 4117, 9425, 3044, 3028, 4211, 4616, 1629, 3978, 6456, 3748, 31, 9225, 3818, 9309, 774, 2700, 4397, 6249, 7612, 112, 5008, 8929, 3789, 2002, 5495, 7910, 4222, 1276, 9159, 8075, 2335, 5108, 5037, 4984, 5316, 9336, 4565, 2416, 3556, 6097, 8425, 277, 8369, 4193, 6540, 9246, 1430, 5005, 6519, 9247, 3697, 6360, 41, 9640, 8022, 9587, 7364, 7977, 2387, 9551, 9758, 4390, 5116, 1108, 4934, 712, 2941, 1440, 8128, 6581, 5029, 7206, 2597, 2416, 6389, 9181, 5302, 371, 1509, 1684, 5432, 8362, 7342, 7847, 9330, 5912, 5289, 5609, 7541, 6495, 3755, 8558, 2143, 2843, 1180, 278, 3008, 509, 8048, 3188, 6307, 2538, 9525, 7444, 2761, 9189, 2898, 9125, 2771, 6928, 2245, 7958, 9325, 6861, 4348, 9379, 2093, 2612, 4016, 3529, 3169, 7074, 8098, 100, 7718, 3383, 4019, 9512, 5935, 6259, 615, 1124, 1933, 2928, 8880, 435, 8282, 2985, 2503, 6845, 8973, 5698, 4922, 4019, 9824, 9934, 9358, 1372, 6027, 743, 7713, 4462, 6134, 9341, 8300, 3801, 6442, 8465, 5339, 9226, 7293, 3017, 104, 3732, 8624, 5704, 9547, 4162, 8634, 4349, 405, 8896, 7211, 2938, 2678, 2251, 4620, 1573, 2747, 944, 5933, 1881, 8990, 5938, 1064, 2620, 3101, 8943, 5839, 3862, 4413, 534, 7980, 2152, 6983, 2525, 5648, 5260, 7788, 7602, 9494, 9210, 391, 2976, 1463, 6267, 3737, 9917, 1325, 4022, 2613, 7375, 4747, 9354, 379, 9429, 5560, 58, 8382, 3194, 8181, 2554, 2974, 6464, 3974, 2870, 4165, 9954, 6958, 8523, 1896, 8344, 5634, 4087, 6611, 618, 2458, 9102, 5061, 4468, 6762, 1849, 614, 4529, 2365, 1907, 8918, 7225, 7446, 8190, 4183, 5539, 6691, 2937, 976, 9634, 6071, 9364, 9153, 6332, 7515, 6009, 8973, 6708, 4891, 1839, 2403, 4519, 1907, 1151, 6150, 1551, 9755, 5902, 5383, 7523, 9487, 8954, 3031, 5129, 7784, 1257, 4334, 3514, 5848, 6927, 8793, 2257, 7315, 8797, 3942, 7151, 5021, 4850, 3408, 8038, 6812, 8637, 4852, 3294, 7770, 5606, 8723, 4191, 5086, 4078, 7668, 950, 600, 6667, 9396, 6415, 8319, 6306, 6147, 3404, 5247, 6675, 1843, 4188, 3335, 4603, 3074, 8692, 1636, 7243, 3496, 8683, 6221, 5778, 8941, 5080, 3420, 7989, 4750, 8932, 9209, 8552, 3963, 3491, 6856, 4864, 1378, 6480, 3801, 6521, 536, 8582, 7606, 4341, 4040, 8709, 9608, 9052, 679, 5091, 4996, 923, 2248, 5321, 1277, 5423, 7273, 9114, 2486, 8405, 4003, 8841, 6691, 2715, 1197, 3300, 845, 1907, 2562, 5072, 9548, 2543, 2323, 3148, 7479, 9598, 9554, 2391, 8701, 2892, 194, 7918, 6419, 7577, 6284, 3444, 2210, 552, 5021, 9260, 3629, 4453, 5918, 4180, 5227, 617, 5991, 9395, 1390, 3296, 704, 4580, 3545, 5580, 2684, 2201, 7722, 6244, 1291, 9698, 1287, 314, 2195, 3445, 8610, 3828, 7459, 5672, 3964, 5045, 1689, 8779, 3352, 2361, 4270, 2967, 9457, 4743, 7960, 9999, 8499, 5539, 7175, 8190, 9329, 364, 2421, 1870, 4742, 1874, 2749, 1384, 6383, 6623, 9265, 977, 4042, 8412, 179, 2939, 5734, 9762, 6134, 199, 6230, 5778, 7756, 3183, 6069, 9433, 8552, 7016, 546, 6225, 4086, 5593, 3131, 3863, 8694, 1754, 7598, 4327, 4459, 4068, 7414, 1762, 1118, 9512, 1490, 300, 1800, 6479, 9341, 6222, 871, 2748, 9123, 9803, 8891, 1079, 3331, 2177, 6771, 2299, 2824, 6943, 1646, 454, 9890, 6180, 5242, 3911, 2527, 8431, 6756, 9182, 9161, 6311, 8949, 2636, 3376, 3715, 1092, 4072, 9473, 5951, 8145, 2202, 2239, 7272, 3027, 2572, 8431, 9641, 8821, 4127, 7111, 1197, 1411, 7767, 3796, 8442, 4012, 6588, 9883, 9756, 5645, 1196, 1502, 5102, 8741, 5221, 9062, 7201, 490, 8185, 7198, 8809, 4370, 4071, 985, 1003, 3862, 5418, 755, 9349, 4410, 9939, 5208, 9944, 4715, 1130, 294, 4084, 5504, 8011, 3318, 3297, 1328, 1108, 9319, 9414, 5641, 5688, 1011, 4339, 6897, 7954, 2934, 2690, 1989, 1282, 1217, 6138, 753, 9710, 433, 8884, 1412, 2163, 1346, 7534, 3828, 6789, 4661, 5227, 1076, 6099, 676, 1061, 6612, 8434, 1305, 2525, 4552, 8545, 7988, 2204, 3674, 4589, 3757, 1578, 2978, 9892, 5545, 344, 4237, 6801, 7728, 2530, 6248, 2500, 411, 4949, 7782, 6235, 473, 6409, 185, 6219, 5121, 2768, 9399, 6516, 686, 8553, 7961, 382, 230, 7781, 2352, 773, 3490, 6528, 74, 6059, 2478, 5566, 173, 6184, 1478, 7724, 3844, 8373, 7151, 6225, 8473, 5945, 3158, 5446, 9823, 6169, 2821, 8613, 2797, 7056, 3704, 9356, 533, 5870, 9870, 845, 9637, 3261, 3271, 2504, 8010, 6611, 8090, 7503, 2452, 1481, 6591, 1436, 665, 6921, 9972, 1969, 1692, 5535, 278, 3244, 2496, 8655, 8933, 5334, 2169, 295, 3790, 9028, 2929, 3076, 4000, 2136, 2979, 8033, 1356, 756, 2040, 473, 9593, 6340, 824, 1918, 6603, 2256, 7084, 7585, 2565, 5303, 5150, 2006, 3397, 5932, 3782, 3596, 7485, 9331, 3950, 9339, 1673, 139, 7484, 5039, 8729, 9507, 6856, 6817, 7286, 7224, 7680, 1672, 6384, 6912, 6718, 9535, 3495], bytes='', events=[], are_ids_encoded=True, _ticks_bars=[], _ticks_beats=[], _ids_decoded=[])\n",
      "Score(ttype=Tick, tpq=16, begin=0, end=2516, tracks=72, notes=595, time_sig=5, key_sig=0, markers=0)\n",
      "TokSequence(tokens=[], ids=[1214, 2241, 1131, 733, 783, 1805, 975, 1874, 788, 1805, 2840, 786, 1880, 724, 3510, 733, 4182, 705, 8713, 3608, 786, 196, 943, 2707, 567, 1178, 1227, 609, 2496, 115, 1214, 590, 2871, 6489, 943, 114, 1214, 1942, 1619, 1432, 904, 1238, 788, 2200, 783, 2200, 2398, 611, 3569, 1787, 1642, 829, 1739, 8005, 7684, 1703, 113, 1214, 605, 4077, 611, 1103, 1453, 592, 4243, 101, 1214, 1992, 897, 3835, 3712, 113, 1214, 4571, 2398, 663, 659, 588, 4077, 663, 208, 967, 5628, 114, 1214, 1885, 1619, 840, 904, 798, 678, 996, 806, 1106, 2624, 663, 4155, 664, 1642, 724, 2369, 611, 869, 2067, 3323, 2290, 114, 1214, 574, 3053, 786, 6693, 6112, 967, 4271, 115, 1214, 1629, 1619, 1391, 904, 2052, 678, 1805, 806, 2052, 2398, 786, 4406, 611, 3569, 724, 2369, 5057, 1178, 1227, 609, 3835, 4271, 2496, 116, 1214, 600, 4077, 786, 3221, 5053, 869, 3323, 114, 1214, 2058, 2624, 5231, 3835, 1920, 2703, 3343, 116, 1214, 605, 3053, 696, 1784, 1325, 4483, 967, 120, 1214, 580, 571, 2394, 1533, 837, 2065, 904, 2065, 783, 2065, 7642, 611, 1220, 805, 2096, 870, 2624, 765, 3569, 1262, 1880, 1346, 1739, 1054, 897, 2137, 3323, 1703, 115, 1214, 603, 2588, 611, 2196, 8296, 2748, 2006, 1568, 757, 2624, 1806, 8161, 3027, 113, 1214, 2506, 1934, 677, 975, 660, 788, 733, 1568, 877, 1252, 698, 783, 733, 3756, 786, 1220, 789, 2096, 870, 2624, 757, 659, 589, 2944, 786, 196, 943, 122, 1214, 1311, 1880, 660, 1540, 611, 3510, 7109, 1178, 609, 2496, 115, 1214, 8800, 7218, 2528, 2624, 870, 659], bytes='', events=[], are_ids_encoded=True, _ticks_bars=[], _ticks_beats=[], _ids_decoded=[])\n",
      "Score(ttype=Tick, tpq=16, begin=0, end=96, tracks=6, notes=151, time_sig=1, key_sig=0, markers=0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from miditok import TokSequence\n",
    "def convert_to_midi(predicted_notes):\n",
    "    # Decode BPE\n",
    "    #return tokenizer.decode_token_ids(predicted_notes)\n",
    "    return tokenizer.decode(predicted_notes)\n",
    "\n",
    "def get_sequence(prediction):\n",
    "    token_ids = prediction.numpy().tolist()\n",
    "    sequence = TokSequence(ids=token_ids, are_ids_encoded=True)\n",
    "    return sequence\n",
    "\n",
    "sequence = get_sequence(output_sequence)\n",
    "print(sequence)\n",
    "midi_path = convert_to_midi(sequence)\n",
    "print(midi_path)\n",
    "midi_path.dump_midi('output.mid')\n",
    "\n",
    "sequence = get_sequence(input_sequence)\n",
    "print(sequence)\n",
    "midi_path = convert_to_midi(sequence)\n",
    "print(midi_path)\n",
    "midi_path.dump_midi('output_original.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
